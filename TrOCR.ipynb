{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dattrinh12/processed-sroie-as-phi-request\")\n",
    "path = path + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_dataset/image_paths.txt', 'a') as image_file:\n",
    "    with open('./test_dataset/labels.txt', 'a') as label_file:\n",
    "        with open(path + '/test_annotations.txt') as file:\n",
    "            for line in file:\n",
    "                name, label = line.split('\\t')\n",
    "                image_file.write(path + '/cropped_images/' + name + '\\n')\n",
    "                label_file.write(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./test_dataset/image_paths.txt\"\n",
    "label_path = \"./test_dataset/labels.txt\"\n",
    "image_paths = []\n",
    "labels = []\n",
    "with open(image_path) as file:\n",
    "    for line in file:\n",
    "        image_paths.append(line[:-1])\n",
    "        \n",
    "with open(label_path) as file:\n",
    "    for line in file:\n",
    "        labels.append(line[:-1])\n",
    "\n",
    "test_image_paths = image_paths[:200]\n",
    "test_labels = labels[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X51007231344_1.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m image = Image.open(temp_path)\n\u001b[32m      6\u001b[39m image = image.convert(\u001b[33m'\u001b[39m\u001b[33mL\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m output = \u001b[43mcluster_enhancement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m output = Image.fromarray(output)\n\u001b[32m      9\u001b[39m output.save(\u001b[33m\"\u001b[39m\u001b[33m./test_dataset/images/\u001b[39m\u001b[33m\"\u001b[39m + temp_path.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Phi\\Xu li anh\\Enhance_Image\\cluster_enhancement.py:69\u001b[39m, in \u001b[36mcluster_enhancement\u001b[39m\u001b[34m(image, kernel_size, alpha, k, p_value)\u001b[39m\n\u001b[32m     67\u001b[39m I_i = I.copy()\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     I_i = \u001b[43mcluster_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Step 2\u001b[39;00m\n\u001b[32m     72\u001b[39m I_d = (I - I_i).copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Phi\\Xu li anh\\Enhance_Image\\cluster_enhancement.py:45\u001b[39m, in \u001b[36mcluster_filter\u001b[39m\u001b[34m(image, alpha, kernel_size)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(result.shape[\u001b[32m1\u001b[39m]):\n\u001b[32m     44\u001b[39m         beta = calculate_beta(image, i + kernel_size // \u001b[32m2\u001b[39m, j + kernel_size // \u001b[32m2\u001b[39m, w, kernel_size)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         result[i, j] = \u001b[43menhance_a_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Phi\\Xu li anh\\Enhance_Image\\cluster_enhancement.py:18\u001b[39m, in \u001b[36menhance_a_pixel\u001b[39m\u001b[34m(image, i, j, w, beta, kernel_size)\u001b[39m\n\u001b[32m     16\u001b[39m perception_view = image[i-padding:i+padding+\u001b[32m1\u001b[39m, j-padding:j+padding+\u001b[32m1\u001b[39m].copy()\n\u001b[32m     17\u001b[39m exponetial = exponetial_matrix(image, i, j, beta, kernel_size)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mexponetial\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mperception_view\u001b[49m\u001b[43m)\u001b[49m / np.sum(w * exponetial)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cancathegioi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2333\u001b[39m, in \u001b[36m_sum_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing `min` or `max` keyword argument when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m'\u001b[39m, a_min, a_max, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2334\u001b[39m                     initial=\u001b[38;5;28;01mNone\u001b[39;00m, where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[32m   2338\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue,\n\u001b[32m   2340\u001b[39m         initial=np._NoValue, where=np._NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from cluster_enhancement import cluster_enhancement\n",
    "temp = []\n",
    "for temp_path in image_paths[:200]:\n",
    "    print(temp_path.split('/')[-1])\n",
    "    image = Image.open(temp_path)\n",
    "    image = image.convert('L')\n",
    "    output = cluster_enhancement(image, kernel_size=15, p_value=5)\n",
    "    output = Image.fromarray(output)\n",
    "    output.save(\"./test_dataset/images/\" + temp_path.split('/')[-1])\n",
    "    temp.append(\"./test_dataset/images/\" + temp_path.split('/')[-1])\n",
    "\n",
    "test_image_paths = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = r'--psm 6 --oem 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIHAKKA INTERNATIONAL SDN BHD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(Image.open(path + \"/cropped_images/X51007231344_1.jpg\"), config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/200\n",
      "path: ./test_dataset/images/X51007231344_5.jpg, predict: ['12.', 'Jalan', 'Tampoi', '7/4,', 'Kawasan', 'Perindustrian'], label: ['12,', 'JALAN', 'TAMPOI', '7/4,KAWASAN', 'PERINDUSTRIAN']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['Tampoi.81200', 'Johor', 'Bahru,', 'Johor'], label: ['TAMPOI,81200', 'JOHOR', 'BAHRU,JOHOR']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['TAX', 'INVOICE'], label: ['TAXINVOICE']\n",
      "path: ./test_dataset/images/X51007231344_7.jpg, predict: ['SR', '100100000035-', '1', 'Meat', '+', '3', 'Vege'], label: ['SR', 'I00100000035-', '1', 'MEAT', '+', '3', 'VEGE']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['4'], label: ['1']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['SR', '1001000001', '70-', 'Imported', 'Veggies'], label: ['SR', 'I00100000170-', 'IMPORTED', 'VEGGIES']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['|'], label: ['1']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['SR', '100100000099-', 'Coke'], label: ['SR', 'I00100000099-', 'COKE']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['|'], label: ['1']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['SR', '=GST', '@6%'], label: ['SR', '=', 'GST', '@6%']\n",
      "path: ./test_dataset/images/X51007231344_6.jpg, predict: ['GOODS', '§OL', 'ARE', 'NOT', 'RETURNABLE,', 'THANK', 'YOU'], label: ['GOODS', 'SOLD', 'ARE', 'NOT', 'RETURNABLE,THANK', 'YOU']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['(JMO0292487-D}'], label: ['(JM0292487-D)']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['NO', '4', 'JALAN', 'PERJIRANAN', '18,'], label: ['NO4,JALAN', 'PERJIRANAN', '10,']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['TAMAN', 'AIR', 'BIRU.'], label: ['TAMAN', 'AIR', 'BIRU,']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['97700', 'PASIR', 'GLUDANG,'], label: ['81700', 'PASIR', 'GUDANG,']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['TEL', ':', 'O7-2614733'], label: ['TEL', ':', '07-2614733']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['FAX', ':', '07-2814733'], label: ['FAX', ':', '07-2514733']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['YONGTA’', 'TS9@YAHOG.CON.MY'], label: ['YONGTAT99@YAHOO.COM.MY']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Gsyrid', '001570348055'], label: ['GST', 'ID', ':', '001570349056']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['TAX', 'INVOICE:'], label: ['TAX', 'INVOICE']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['oc', 'No,'], label: ['DOC', 'NO.']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['CS5000358603'], label: [':', 'CS00035863']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Date.', '13/03/2018'], label: ['DATE:', '13/03/2018']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['USER'], label: [':', 'USER']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Salesperson', '.'], label: ['SALESPERSON:']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Reef:'], label: ['REF:']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['tern'], label: ['ITEM']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Oty'], label: ['QTY']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['SirPace'], label: ['S/PRICE']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Lhmauni'], label: ['AMOUNT']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['IBO7'], label: ['2697']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['ai', 'Ul'], label: ['48.00']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['50.865'], label: ['50.88']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['AO', 'G6'], label: ['50.88']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['iat'], label: ['SR']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['10°', 'WING', 'COMPASS'], label: ['10\"WING', 'COMPASS']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['FAB'], label: ['5736']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['1.00', 'Stel'], label: ['1.00', 'SET']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['a7.17'], label: ['47.17']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['50', 'Ul'], label: ['50.00']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['oR'], label: ['SR']\n",
      "path: ./test_dataset/images/X51007231344_5.jpg, predict: ['1/97-3/4\"', '12PCS', 'HOLLOW', 'PUNCH', 'SET'], label: ['1/8\"-3/4\"', '12PCS', 'HOLLOW', 'PUNCH', 'SET']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Total', 'Gly:'], label: ['TOTAL', 'QTY:']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['7900.48'], label: ['100.88']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['Total', 'Sales', '(Excluding', 'GST)'], label: ['TOTAL', 'SALES(EXCLUDING', 'GST)', ':']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['05.17'], label: ['95.17']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['enee'], label: ['0.00']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['571'], label: ['5.71']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Rounding'], label: ['ROUNDLNG', ':']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['OO?'], label: ['0.02']\n",
      "path: ./test_dataset/images/X51007231344_5.jpg, predict: ['“otal', 'Sales', '(Inclusive', 'of', 'GST)', '©'], label: ['TOTAL', 'SALES(INCLUSIVE', 'OF', 'GST)', ':']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['400,96'], label: ['100.90']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['CASH', '¢'], label: ['CASH', ':']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['407.00'], label: ['101.00']\n",
      "Processing 100/200\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['BST', 'SUMMARY'], label: ['GST', 'SUMMARY']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Taz', 'Coda'], label: ['TAX', 'CODE']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['No'], label: ['%']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Amt', 'i', 'RM)'], label: ['AMT(RM)']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Tax', '(Ri)'], label: ['TAX(RM)']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['She'], label: ['SR']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['5'], label: ['6']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['65.17'], label: ['95.17']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Ay'], label: ['5.71']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['95', '17'], label: ['95.17']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['%', '#4]'], label: ['5.71']\n",
      "path: ./test_dataset/images/X51007231344_5.jpg, predict: ['Seksyen', '9,', 'Bandar', 'Mankota', 'Cheras,'], label: ['SEKSYEN', '9,', 'BANDAR', 'MAHKOTA', 'CHERAS,']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['49900', 'Cheras.', 'Selanoor'], label: ['43200', 'CHERAS,', 'SELANGOR']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['GST', 'REG', 'NO:', '001385787520'], label: ['GST', 'REG', 'NO:', '001355787520']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['INV', 'No.:;', '1047523'], label: ['INV', 'NO.:', '1047523']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Date', '°«', '16-03-2018'], label: ['DATE:', '16-03-2018']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['19-07°10'], label: ['12:07:10']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Nescriotion'], label: ['DESCRIPTION']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Tota]'], label: ['TOTAL']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Koni', '(B)'], label: ['KOPI', '(B)']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['9', 'O01)'], label: ['2.20']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['1x'], label: ['1', 'X']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['2,20'], label: ['2.20']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['9', '9'], label: ['2.20']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['4,40'], label: ['4.40']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['4x'], label: ['4', 'X']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['0,20'], label: ['0.20']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['Total', 'QTY;', '8'], label: ['TOTAL', 'QTY:', '8']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Q', '(\\\\7'], label: ['9.07']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['9.680'], label: ['9.60']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['g.6B60'], label: ['9.60']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['CASH', ':'], label: ['CASH:']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['9,60'], label: ['9.60']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['Tax(RM)'], label: ['TAX', '(RM)']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['(@', '6X)'], label: ['(@', '6%)']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['9,07'], label: ['9.07']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['0,53'], label: ['0.53']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['UNTT', '.1-044B,', 'VIVACITY', 'MEGAMALL,'], label: ['UNIT', 'L1-044B,', 'VIVACITY', 'MEGAMALL,']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['GST', '1D', ':', '000349356032'], label: ['GST', 'ID', ':', '000349356032']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['+', '880'], label: [':', '880']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: [':', '39/03/2018', '20:19:38'], label: [':', '29/03/2018', '20:19:38']\n",
      "path: ./test_dataset/images/X51007231344_3.jpg, predict: ['‘', 'Then', 'Fiona'], label: [':', 'THEN', 'FIONA']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['va(y'], label: [':', '0']\n",
      "path: ./test_dataset/images/X51007231344_5.jpg, predict: ['PURE', 'ECG', 'SNAIL', 'MOISTURE', 'GEL'], label: ['PURE', 'ECO', 'SNAIL', 'MOISTURE', 'GEL']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['BDVEOCO8CO'], label: ['BD06000800']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['39,', '90'], label: ['39.90']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Ttem', 'Count'], label: ['ITEM', 'COUNT']\n",
      "path: ./test_dataset/images/X51007231344_4.jpg, predict: ['fotal', 'Sales', 'Incl.', 'GSI'], label: ['TOTAL', 'SALES', 'INCL.', 'GST']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['39.', '90'], label: ['39.90']\n",
      "path: ./test_dataset/images/X51007231344_2.jpg, predict: ['Kounding', 'Adjustment'], label: ['ROUNDING', 'ADJUSTMENT']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['0.', '00'], label: ['0.00']\n",
      "path: ./test_dataset/images/X51007231344_1.jpg, predict: ['39.', '90'], label: ['39.90']\n"
     ]
    }
   ],
   "source": [
    "matchs = 0\n",
    "predict_size = 0\n",
    "label_size = 0\n",
    "f1 = 0\n",
    "\n",
    "for i in range(len(test_image_paths)):\n",
    "    if(i % 100 == 0):\n",
    "        print(f\"Processing {i}/{len(test_image_paths)}\")\n",
    "    get = False\n",
    "    predict = pytesseract.image_to_string(Image.open(test_image_paths[i]), config=custom_config).split('\\n')[0].split(' ')\n",
    "    label = test_labels[i].split(' ');\n",
    "    predict_size += len(predict)\n",
    "    label_size += len(label)\n",
    "    for i in range(min(len(predict), len(label))):\n",
    "        if predict[i].lower() == label[i].lower():\n",
    "            matchs += 1;\n",
    "        else:\n",
    "            get = True\n",
    "    if get:\n",
    "        print(f\"path: {test_image_paths[i]}, predict: {predict}, label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.625\n"
     ]
    }
   ],
   "source": [
    "print(matchs / predict_size, matchs / label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing.\n",
      "Processing 0/200\n",
      "Processing 100/200\n",
      "0.6055276381909548 0.6276041666666666\n",
      "Finished preprocessing.\n",
      "Processing 0/200\n",
      "Processing 100/200\n",
      "0.5919395465994962 0.6119791666666666\n",
      "Finished preprocessing.\n",
      "Processing 0/200\n",
      "Processing 100/200\n",
      "0.6040100250626567 0.6276041666666666\n",
      "Finished preprocessing.\n",
      "Processing 0/200\n",
      "Processing 100/200\n",
      "0.5979899497487438 0.6197916666666666\n"
     ]
    }
   ],
   "source": [
    "sizes = [27, 29, 33, 35]\n",
    "for size in sizes:\n",
    "    temp = []\n",
    "    for temp_path in image_paths[:200]:\n",
    "        #print(temp_path.split('/')[-1])\n",
    "        image = Image.open(temp_path)\n",
    "        image = image.convert('L')\n",
    "        output = cluster_enhancement(image, kernel_size=size, p_value=5)\n",
    "        output = Image.fromarray(output)\n",
    "        output.save(\"./test_dataset/images/\" + temp_path.split('/')[-1])\n",
    "        temp.append(\"./test_dataset/images/\" + temp_path.split('/')[-1])\n",
    "\n",
    "    print(\"Finished preprocessing.\")\n",
    "    test_image_paths = temp \n",
    "    \n",
    "    matchs = 0\n",
    "    predict_size = 0\n",
    "    label_size = 0\n",
    "    f1 = 0\n",
    "\n",
    "    for i in range(len(test_image_paths)):\n",
    "        if(i % 100 == 0):\n",
    "            print(f\"Processing {i}/{len(test_image_paths)}\")\n",
    "        get = False\n",
    "        predict = pytesseract.image_to_string(Image.open(test_image_paths[i]), config=custom_config).split('\\n')[0].split(' ')\n",
    "        label = test_labels[i].split(' ');\n",
    "        predict_size += len(predict)\n",
    "        label_size += len(label)\n",
    "        for i in range(min(len(predict), len(label))):\n",
    "            if predict[i].lower() == label[i].lower():\n",
    "                matchs += 1;\n",
    "            else:\n",
    "                get = True\n",
    "        if get:\n",
    "            #print(f\"path: {test_image_paths[i]}, predict: {predict}, label: {label}\")\n",
    "            pass\n",
    "\n",
    "    print(matchs / predict_size, matchs / label_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
